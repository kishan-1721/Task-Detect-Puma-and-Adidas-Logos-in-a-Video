---

# Puma & Adidas Logo Detection â€” README

**Project:** Logo Detection in Video (Puma & Adidas)
**Author:** Kishan Patel

---

## ğŸ“Œ Summary

This repository contains the code, dataset configuration, training notebook, and inference script for detecting **Puma** and **Adidas** logos in video frames using a custom-trained YOLO-based object detection model.
The model was trained on a GPU environment (Google Colab with CUDA). Inference results are generated on a sample video due to submission size limits.

---

## ğŸ“‘ Table of Contents

* [Project Overview](#project-overview)
* [Dataset Details](#dataset-details)
* [Preprocessing & Augmentation](#preprocessing--augmentation)
* [Train / Val / Test Split](#train--val--test-split)
* [Model Recommendation & Training Setup](#model-recommendation--training-setup)
* [Training Steps (Colab)](#training-steps-colab)
* [Inference (Video) & CSV Output](#inference-video--csv-output)
* [Repository Structure](#repository-structure)
* [Notes & Limitations](#notes--limitations)
* [How to Reproduce (Quick Commands)](#how-to-reproduce-quick-commands)
* [Contact](#contact)

---

## ğŸ“ Project Overview

The goal of this project is to:

* Detect Puma and Adidas logos in video frames
* Annotate each frame with bounding boxes
* Generate a labeled output video
* Export detections into a structured CSV file

This project uses a **custom YOLO model** trained on an augmented dataset of 352 images. Due to file size constraints, inference and outputs were generated on a smaller sample video.

---

## ğŸ“‚ Dataset Details

* **Base images:** ~130 manually collected + Roboflow augmented
* **Final dataset size:** 352 images
* **Annotation format:** YOLO (normalized x_center, y_center, width, height)
* **Classes:**

  1. puma
  2. adidas

### âœ” Preprocessing applied (Roboflow)

* Auto-orientation (EXIF rotation fix)
* Resize to **512Ã—512 (stretched)**

### âœ” Augmentations applied

* 50% horizontal flip
* 50% vertical flip
* Random 90Â° rotations (0Â°, 90Â°, 180Â°, 270Â°)
* Random crop (0â€“20%)
* Random rotation (âˆ’15Â° to +15Â°)

---

## ğŸ”§ Preprocessing Notes

* Images resized to 512Ã—512 for consistency
* Augmentation improves robustness to orientation and partial visibility
* Very small logos were minimized due to detection difficulty on limited data

---

## ğŸ”€ Train / Val / Test Split

| Split      | Images |
| ---------- | ------ |
| Train      | 333    |
| Validation | 10     |
| Test       | 9      |

All split folders contain corresponding `images/` and `labels/`.

---

## ğŸ§  Model Recommendation & Training Setup

* **Model family used:** YOLO (Ultralytics) â€” *yolo11n*
* **Why YOLO?**

  * Fast
  * Good for small-object detection
  * Easy video inference pipeline
* **Training hardware:** Google Colab GPU (T4)

### Suggested Hyperparameters

| Parameter  | Value              |
| ---------- | ------------------ |
| Epochs     | 300                |
| Image size | 640                |
| Batch size | 16                 |
| Optimizer  | Default (SGD/Adam) |

### Example `data.yaml`

```yaml
train: ../data/images/train
val: ../data/images/valid
test: ../data/images/test

nc: 2
names: ["puma", "adidas"]
```

---

## ğŸš€ Training Steps (Colab)

1. Enable GPU runtime
2. Install dependencies:

```bash
pip install ultralytics roboflow opencv-python-headless pandas
```

3. Mount Drive:

```python
from google.colab import drive
drive.mount('/content/drive')
```

4. Train the model:

```python
from ultralytics import YOLO

model = YOLO("yolo11n.pt")  # pretrained weights

results = model.train(
    data="/content/Brand_Logo_Detection-3/data.yaml",
    epochs=300,
    imgsz=640
)
```

5. Best weights will be saved under:

```
runs/detect/train/weights/best.pt
```

---

## ğŸ¥ Inference (Video) & CSV Output

### Goal

* Process each frame
* Detect Puma/Adidas
* Save annotated video
* Save CSV with:

| frame_no | brand | confidence | x1 | y1 | x2 | y2 |

### Example Script (provided in repo)

```bash
python scripts/detect_video.py \
    --weights runs/detect/train/weights/best.pt \
    --source inputs/sample_video.mp4 \
    --output output/output_labeled_video.mp4 \
    --csv output/detections.csv
```

A sample video and its inference result are included in the `inputs/` and `output/` directories.

---

## ğŸ“ Repository Structure

```
Main-Directory/
â”œâ”€â”€ data/                      # Dataset (train/valid/test)
â”œâ”€â”€ models/                    # Saved model weights (best.pt)
â”œâ”€â”€ runs/                      # YOLO training logs + metrics
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ Model_Train.ipynb      # Training and evaluation notebook
â”œâ”€â”€ inputs/                    # Sample input videos
â”œâ”€â”€ output/                    # Output videos + CSV results
â”œâ”€â”€ README.md                  # Documentation
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ data.yaml                  # YOLO dataset config
â””â”€â”€ yolo11n.pt                 # Pretrained YOLO weights
```

---

## âš ï¸ Notes & Limitations

* 512Ã—512 *stretched* resize may distort logos
* Very small logos remain challenging without high-resolution data
* Only a **sample video** is included due to submission limitations

---

## ğŸ’¡ How to Reproduce (Quick Commands)

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Train model

```bash
python scripts/train.py --data data.yaml --epochs 300 --imgsz 640 --batch 16
```

### 3ï¸âƒ£ Run inference

```bash
python scripts/detect_video.py \
    --weights models/best.pt \
    --source inputs/sample_video.mp4 \
    --output output/output_labeled_video.mp4 \
    --csv output/detections.csv
```

---

## ğŸ“© Contact

For support, notebook access, or clarifications:

**Kishan Patel**

---
